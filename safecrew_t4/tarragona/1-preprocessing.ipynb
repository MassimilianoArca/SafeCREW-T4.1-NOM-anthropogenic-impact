{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Daily Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(\"..\", \"data\", \"tarragona\")\n",
    "raw_data_folder = os.path.join(data_folder, \"raw\")\n",
    "clean_data_folder = os.path.join(data_folder, \"clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dict = {}\n",
    "\n",
    "datasets_dict[\"TORTOSA\"] = {}\n",
    "datasets_dict[\"GUIAMETS\"] = {}\n",
    "datasets_dict[\"MEQUINENZA\"] = {}\n",
    "datasets_dict[\"XERTA\"] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(raw_data_folder):\n",
    "    location = file.split(\"_\")[0]\n",
    "    feature_name = \"_\".join(file.split(\"_\")[1:-2])\n",
    "    if file.endswith(\".csv\"):\n",
    "        datasets_dict[location][feature_name] = pd.read_csv(\n",
    "            filepath_or_buffer=os.path.join(raw_data_folder, file),\n",
    "            sep=\";\",\n",
    "            decimal=\",\",\n",
    "            header=0,\n",
    "            encoding=\"utf-8\",\n",
    "        )\n",
    "    elif (file.endswith(\".xlsx\")):\n",
    "        datasets_dict[location][feature_name] = pd.read_excel(\n",
    "            os.path.join(raw_data_folder, file),\n",
    "            header=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs = datasets_dict[\"TORTOSA\"]\n",
    "guiamets_dfs = datasets_dict[\"GUIAMETS\"]\n",
    "mequinenza_dfs = datasets_dict[\"MEQUINENZA\"]\n",
    "xerta_dfs = datasets_dict[\"XERTA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tortosa Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The water temperature has two datasets, but the excel one has no missing values\n",
    "tortosa_dfs[\"watertemperature\"].isna().sum() / tortosa_dfs[\n",
    "    \"watertemperature\"\n",
    "].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs[\"water_temperature\"].isna().sum() / tortosa_dfs[\n",
    "    \"water_temperature\"\n",
    "].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs.pop(\"water_temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cumulated rainfall data since it is the only csv file\n",
    "tortosa_dfs[\"cumulated_rainfall_24h\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fecha column is the one to take into account since\n",
    "# it is equal to the Fecha acumulado column in the same dataframe\n",
    "# but it has no missing values\n",
    "mask = (\n",
    "    tortosa_dfs[\"cumulated_rainfall_24h\"][\"Fecha acumulado\"]\n",
    "    == tortosa_dfs[\"cumulated_rainfall_24h\"][\"fecha\"]\n",
    ")\n",
    "tortosa_dfs[\"cumulated_rainfall_24h\"][mask == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs[\"cumulated_rainfall_24h\"].isna().sum() / tortosa_dfs[\n",
    "    \"cumulated_rainfall_24h\"\n",
    "].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs[\"cumulated_rainfall_24h\"] = tortosa_dfs[\n",
    "    \"cumulated_rainfall_24h\"\n",
    "][[\"fecha\", \"Acumulado\"]].rename(\n",
    "    columns={\"fecha\": \"DateTime\", \"Acumulado\": \"Average\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs[\"conductivity\"].isna().sum() / tortosa_dfs[\n",
    "    \"conductivity\"\n",
    "].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs[\"flowriver\"].isna().sum() / tortosa_dfs[\"flowriver\"].shape[\n",
    "    0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs[\"turbidity\"].isna().sum() / tortosa_dfs[\"turbidity\"].shape[\n",
    "    0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in tortosa_dfs.items():\n",
    "    if feature != \"cumulated_rainfall_24h\":\n",
    "        df.rename(\n",
    "            columns={\n",
    "                \"Fecha\": \"DateTime\",\n",
    "                \"Promedio\": \"Average\",\n",
    "                \"Máximo\": \"Maximum\",\n",
    "                \"Mínimo\": \"Minimum\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in tortosa_dfs.values():\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "    df[df.columns.difference([\"DateTime\"])] = df[\n",
    "        df.columns.difference([\"DateTime\"])\n",
    "    ].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the datasets\n",
    "for feature, df in tortosa_dfs.items():\n",
    "    print(f\"{feature}: {df.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the moment, drop the missing values\n",
    "for feature, df in tortosa_dfs.items():\n",
    "    tortosa_dfs[feature] = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers Detection and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(tortosa_dfs.keys()), figsize=(30, 10))\n",
    "\n",
    "for i, (feature, df) in enumerate(tortosa_dfs.items()):\n",
    "    if feature == \"cumulated_rainfall_24h\":\n",
    "        gtz_df = df[df[\"Average\"] > 0]\n",
    "        sns.boxplot(data=gtz_df, y=\"Average\", ax=axs[i])\n",
    "        # number of values = 0\n",
    "        print(df[df[\"Average\"] == 0].shape[0] / df.shape[0])\n",
    "        print(df.shape[0])\n",
    "    else:\n",
    "        sns.boxplot(data=df, y=\"Average\", ax=axs[i])\n",
    "\n",
    "    # remove y-axis label\n",
    "    axs[i].set_ylabel(\"\")\n",
    "    axs[i].set_title(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in tortosa_dfs.items():\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    sns.histplot(data=df[\"Average\"], kde=True)\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in tortosa_dfs.items():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(data=df, y=\"Average\")\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in tortosa_dfs.items():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data - Feature-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How I determined acceptable ranges of values for each feature\n",
    "\n",
    "* Turbidity: [DataStream](https://datastream.org/en-ca/guidebook/turbidity#:~:text=Turbidity%20values%20less%20than%2010,be%20more%20than%20100%20NTU.) says that high levels of turbidity are > 100 NTU. [In-Situ](https://in-situ.com/us/faq/water-quality-information/what-are-typical-turbidity-values-in-natural-environments#:~:text=Turbidity%20values%20in%20natural%20environments%20can%20range%20from%20as%20low,a%20major%20storm%20runoff%20event.) says that levels of turbidity > 100 NTU are unsafe for most aquatic life. [Wikipedia](https://in-situ.com/us/faq/water-quality-information/what-are-typical-turbidity-values-in-natural-environments#:~:text=Turbidity%20values%20in%20natural%20environments%20can%20range%20from%20as%20low,a%20major%20storm%20runoff%20event.) says that the Ebro river has a wide ecosystem. Given these considerations, **I decided to consider valid the range of values between 0 and 150 NTU**.\n",
    "\n",
    "* Daily Cumulated Rainfall: This [link](https://weather-and-climate.com/average-monthly-precipitation-Rainfall,tarragona-catalonia-es,Spain) says that the average monthly amount of precipitation ranges from 20 mm to 80 mm. On worst case scenario (80 mm in a month, which is october), considering that [here](https://weatherspark.com/y/45958/Average-Weather-in-Tarragona-Spain-Year-Round) it says that on average on october it rains ~ 6 days, we can assume that in a day it can rain up to ~ **13 mm. I decided to take this value as a threshold.**\n",
    "\n",
    "* Flow River: [Wikipedia](https://en.wikipedia.org/wiki/Ebro#Flow_and_floods) confirms the domain of the plot, so no cleaning is required.\n",
    "\n",
    "* Water Temperature: from the plot it is clear that at the beginning of the time series there is an unusual spike. Therefore, **only the values of that spike are removed.**\n",
    "\n",
    "* Conductivity: same as water temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turbidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turb_df = tortosa_dfs[\"turbidity\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(data=turb_df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "plt.axhline(y=threshold, color=\"r\", linestyle=\"--\", label=\"Threshold\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turb_df = turb_df[turb_df[\"Average\"] < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(data=turb_df, x=\"DateTime\", y=\"Average\", label=\"Average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs[\"turbidity\"] = turb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daily Cumulated Rainfall\n",
    "\n",
    "UPDATE: no removal of data since I found out that those values are in a valid range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_df = tortosa_dfs[\"cumulated_rainfall_24h\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(data=rain_df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "plt.axhline(y=threshold, color=\"r\", linestyle=\"--\", label=\"Threshold\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rain_df = rain_df[rain_df[\"Average\"] < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(data=rain_df, x=\"DateTime\", y=\"Average\", label=\"Average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs[\"cumulated_rainfall_24h\"] = rain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Water Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_df = tortosa_dfs[\"watertemperature\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(data=water_df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "plt.axhline(y=threshold, color=\"r\", linestyle=\"--\", label=\"Threshold\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_df = water_df[water_df[\"Average\"] < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(data=water_df, x=\"DateTime\", y=\"Average\", label=\"Average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs[\"watertemperature\"] = water_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_df = tortosa_dfs[\"conductivity\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_threshold = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(data=cond_df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "plt.axhline(\n",
    "    y=upper_threshold, color=\"r\", linestyle=\"--\", label=\"Threshold\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_df = cond_df[cond_df[\"Average\"] < upper_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(data=cond_df, x=\"DateTime\", y=\"Average\", label=\"Average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_threshold = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_df = cond_df[cond_df[\"Average\"] > lower_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(data=cond_df, x=\"DateTime\", y=\"Average\", label=\"Average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_dfs[\"conductivity\"] = cond_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show uncovered days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in tortosa_dfs.items():\n",
    "    df = df.set_index(\"DateTime\")\n",
    "\n",
    "    all_dates = pd.date_range(\n",
    "        start=df.index.min(), end=df.index.max(), freq=\"D\"\n",
    "    )\n",
    "    df = df.reindex(all_dates, fill_value=None)\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"DateTime\"}, inplace=True)\n",
    "    tortosa_dfs[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in tortosa_dfs.items():\n",
    "    print(feature)\n",
    "    print()\n",
    "    print(df.isna().sum())\n",
    "    print()\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_df = {}\n",
    "\n",
    "for feature, df in tortosa_dfs.items():\n",
    "    df[\"is_missing\"] = df[\"Average\"].isna()\n",
    "\n",
    "    lower_threshold = None\n",
    "    upper_threshold = None\n",
    "\n",
    "    label = \"\"\n",
    "    if feature == \"cumulated_rainfall_24h\":\n",
    "        label = \"Daily Cumulated Rainfall (mm)\"\n",
    "\n",
    "    elif feature == \"conductivity\":\n",
    "        label = \"Conductivity (µS/cm)\"\n",
    "        upper_threshold = 2500\n",
    "        lower_threshold = 250\n",
    "\n",
    "    elif feature == \"flowriver\":\n",
    "        label = \"Flow River (m³/s)\"\n",
    "\n",
    "    elif feature == \"turbidity\":\n",
    "        label = \"Turbidity (NTU)\"\n",
    "        upper_threshold = 150\n",
    "\n",
    "    elif feature == \"watertemperature\":\n",
    "        label = \"Water Temperature (°C)\"\n",
    "        upper_threshold = 35\n",
    "\n",
    "    missing_values_perc = (df[\"is_missing\"].sum() / df.shape[0]) * 100\n",
    "    missing_values_perc = missing_values_perc.round(2)\n",
    "\n",
    "    missing_values_df[feature] = missing_values_perc\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(\n",
    "        data=df, x=\"DateTime\", y=\"Average\", label=\"Observed Values\"\n",
    "    )\n",
    "\n",
    "    # Get current axis\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Set major ticks format\n",
    "    years = mdates.YearLocator()  # every year\n",
    "    years_fmt = mdates.DateFormatter(\"%Y\")\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(years_fmt)\n",
    "\n",
    "    for date in df[df[\"is_missing\"]][\"DateTime\"]:\n",
    "        plt.axvline(\n",
    "            x=date, ymin=0.01, ymax=0.99, color=\"grey\", alpha=0.1\n",
    "        )\n",
    "\n",
    "    # Plot an empty line with a label for the legend\n",
    "    plt.plot([], [], color=\"grey\", alpha=0.1, label=\"Missing values\")\n",
    "\n",
    "    if lower_threshold:\n",
    "        plt.axhline(\n",
    "            y=lower_threshold,\n",
    "            color=\"purple\",\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Lower Threshold: {lower_threshold}\",\n",
    "        )\n",
    "\n",
    "    if upper_threshold:\n",
    "        plt.axhline(\n",
    "            y=upper_threshold,\n",
    "            color=\"r\",\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Upper Threshold: {upper_threshold}\",\n",
    "        )\n",
    "\n",
    "    plt.title(\n",
    "        label + \" - \" + str(missing_values_perc) + \"% of missing values\"\n",
    "    )\n",
    "\n",
    "    plt.ylabel(label)\n",
    "\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    print(feature)\n",
    "    print(\"N samples:\", df.shape[0])\n",
    "\n",
    "    # compute the number of suspicious values\n",
    "    n_sus = 0\n",
    "    if lower_threshold:\n",
    "        n_sus += df[df[\"Average\"] < lower_threshold].shape[0]\n",
    "\n",
    "    if upper_threshold:\n",
    "        n_sus += df[df[\"Average\"] > upper_threshold].shape[0]\n",
    "\n",
    "    print(\"N suspicious:\", n_sus)\n",
    "\n",
    "\n",
    "missing_values_df = pd.DataFrame(\n",
    "    missing_values_df.items(), columns=[\"Feature\", \"Missing values (%)\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Average column to the feature name for each dataframe\n",
    "# and keep only the DateTime and the feature column\n",
    "for feature, df in tortosa_dfs.items():\n",
    "    df.rename(columns={\"Average\": feature}, inplace=True)\n",
    "    df = df[[\"DateTime\", feature, \"is_missing\"]]\n",
    "    df.rename(\n",
    "        columns={\"is_missing\": feature + \"_is_missing\"}, inplace=True\n",
    "    )\n",
    "    tortosa_dfs[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all xerta datasets into a single dataframe\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# Get a list of all dataframes\n",
    "dfs = list(tortosa_dfs.values())\n",
    "\n",
    "# Use reduce to merge all dataframes\n",
    "tortosa_df = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=\"DateTime\"), dfs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NaNs\n",
    "\n",
    "For non-seasonal data a linear interpolation is performed.\n",
    "For seasonal data the interpolation is performed by first removing the season component and then perform a linear interpolation on the trend + residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with interpolation\n",
    "df_fill = tortosa_df.copy()\n",
    "df_fill.set_index(\"DateTime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill = df_fill.interpolate(method=\"time\", limit_direction=\"both\")\n",
    "df_fill.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data for each feature\n",
    "for feature in tortosa_dfs.keys():\n",
    "    df_fill[feature + \"_is_missing\"] = df_fill[feature].isna()\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(\n",
    "        data=df_fill,\n",
    "        x=\"DateTime\",\n",
    "        y=feature,\n",
    "        label=feature + \" imputed\",\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        data=tortosa_df,\n",
    "        x=\"DateTime\",\n",
    "        y=feature,\n",
    "        label=feature,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    missing_values_perc = (\n",
    "        df_fill[feature + \"_is_missing\"].sum() / df_fill.shape[0]\n",
    "    ) * 100\n",
    "    missing_values_perc = missing_values_perc.round(2)\n",
    "\n",
    "    plt.title(\n",
    "        feature\n",
    "        + \" - \"\n",
    "        + str(missing_values_perc)\n",
    "        + \"% of missing values\"\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tortosa_df = df_fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guiamets Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of missing values\n",
    "guiamets_dfs[\"cumulated_rainfall_24h\"].isna().sum() / guiamets_dfs[\n",
    "    \"cumulated_rainfall_24h\"\n",
    "].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_dfs[\"environmental_temperature\"].isna().sum() / guiamets_dfs[\n",
    "    \"environmental_temperature\"\n",
    "].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_dfs[\"cumulated_rainfall_24h\"].columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_dfs[\"cumulated_rainfall_24h\"].drop(\n",
    "    columns=[\"Fecha m�ximo\", \"M�ximo\", \"Fecha acumulado\"], inplace=True\n",
    ")\n",
    "guiamets_dfs[\"environmental_temperature\"].drop(\n",
    "    columns=[\"Fecha m�ximo\", \"Fecha m�nimo\"], inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_dfs[\"cumulated_rainfall_24h\"].rename(\n",
    "    columns={\"fecha\": \"DateTime\", \"Acumulado\": \"Average\"}, inplace=True\n",
    ")\n",
    "\n",
    "guiamets_dfs[\"environmental_temperature\"].rename(\n",
    "    columns={\n",
    "        \"fecha\": \"DateTime\",\n",
    "        \"Media\": \"Average\",\n",
    "        \"M�nimo\": \"Minimum\",\n",
    "        \"M�ximo\": \"Maximum\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in guiamets_dfs.values():\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "    df[df.columns.difference([\"DateTime\"])] = df[\n",
    "        df.columns.difference([\"DateTime\"])\n",
    "    ].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the datasets\n",
    "for feature, df in guiamets_dfs.items():\n",
    "    print(f\"{feature}: {df.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the moment, drop the missing values\n",
    "for feature, df in guiamets_dfs.items():\n",
    "    guiamets_dfs[feature] = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers Detection and Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in guiamets_dfs.items():\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    sns.histplot(data=df[\"Average\"], kde=True)\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in guiamets_dfs.items():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(data=df, y=\"Average\")\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in guiamets_dfs.items():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data - Feature-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How I determined acceptable ranges of values for each feature\n",
    "\n",
    "* Daily Cumulated Rainfall: This [link](https://weather-and-climate.com/average-monthly-precipitation-Rainfall,tarragona-catalonia-es,Spain) says that the average monthly amount of precipitation ranges from 20 mm to 80 mm. On worst case scenario (80 mm in a month, which is october), considering that [here](https://weatherspark.com/y/45958/Average-Weather-in-Tarragona-Spain-Year-Round) it says that on average on october it rains ~ 6 days, we can assume that in a day it can rain up to ~ **13 mm. I decided to take this value as a threshold.**\n",
    "\n",
    "* Air Temperature: the range of values is valid. Therefore, **no removal is necessary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daily Cumulated Rainfall\n",
    "\n",
    "UPDATE: no removal of data since I found out that those values are in a valid range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_df = guiamets_dfs[\"cumulated_rainfall_24h\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(data=rain_df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "plt.axhline(y=threshold, color=\"r\", linestyle=\"--\", label=\"Threshold\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rain_df = rain_df[rain_df[\"Average\"] < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(data=rain_df, x=\"DateTime\", y=\"Average\", label=\"Average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_dfs[\"cumulated_rainfall_24h\"] = rain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show uncovered days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in guiamets_dfs.items():\n",
    "    df = df.set_index(\"DateTime\")\n",
    "\n",
    "    all_dates = pd.date_range(\n",
    "        start=df.index.min(), end=df.index.max(), freq=\"D\"\n",
    "    )\n",
    "    df = df.reindex(all_dates, fill_value=None)\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"DateTime\"}, inplace=True)\n",
    "    guiamets_dfs[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in guiamets_dfs.items():\n",
    "    print(feature)\n",
    "    print()\n",
    "    print(df.isna().sum())\n",
    "    print()\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_df = {}\n",
    "\n",
    "for feature, df in guiamets_dfs.items():\n",
    "    df[\"is_missing\"] = df[\"Average\"].isna()\n",
    "\n",
    "    label = \"\"\n",
    "    if feature == \"cumulated_rainfall_24h\":\n",
    "        label = \"Daily Cumulated Rainfall (mm)\"\n",
    "\n",
    "    elif feature == \"environmental_temperature\":\n",
    "        label = \"Air Temperature (°C)\"\n",
    "\n",
    "    missing_values_perc = (df[\"is_missing\"].sum() / df.shape[0]) * 100\n",
    "    missing_values_perc = missing_values_perc.round(2)\n",
    "\n",
    "    missing_values_df[feature] = missing_values_perc\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(\n",
    "        data=df, x=\"DateTime\", y=\"Average\", label=\"Observed Values\"\n",
    "    )\n",
    "\n",
    "    # Get current axis\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Set major ticks format\n",
    "    years = mdates.YearLocator()  # every year\n",
    "    years_fmt = mdates.DateFormatter(\"%Y\")\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(years_fmt)\n",
    "\n",
    "    for date in df[df[\"is_missing\"]][\"DateTime\"]:\n",
    "        plt.axvline(\n",
    "            x=date, ymin=0.01, ymax=0.99, color=\"grey\", alpha=0.1\n",
    "        )\n",
    "\n",
    "    # Plot an empty line with a label for the legend\n",
    "    plt.plot([], [], color=\"grey\", alpha=0.1, label=\"Missing values\")\n",
    "\n",
    "    plt.title(\n",
    "        label + \" - \" + str(missing_values_perc) + \"% of missing values\"\n",
    "    )\n",
    "\n",
    "    plt.ylabel(label)\n",
    "\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "    print(feature)\n",
    "    print(\"N samples:\", df.shape[0])\n",
    "\n",
    "    # compute the number of suspicious values\n",
    "    n_sus = 0\n",
    "    if lower_threshold:\n",
    "        n_sus += df[df[\"Average\"] < lower_threshold].shape[0]\n",
    "\n",
    "    if upper_threshold:\n",
    "        n_sus += df[df[\"Average\"] > upper_threshold].shape[0]\n",
    "\n",
    "    print(\"N suspicious:\", n_sus)\n",
    "\n",
    "missing_values_df = pd.DataFrame(\n",
    "    missing_values_df.items(), columns=[\"Feature\", \"Missing values (%)\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Average column to the feature name for each dataframe\n",
    "# and keep only the DateTime and the feature column\n",
    "for feature, df in guiamets_dfs.items():\n",
    "    df.rename(columns={\"Average\": feature}, inplace=True)\n",
    "    df = df[[\"DateTime\", feature, \"is_missing\"]]\n",
    "    df.rename(\n",
    "        columns={\"is_missing\": feature + \"_is_missing\"}, inplace=True\n",
    "    )\n",
    "    guiamets_dfs[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all xerta datasets into a single dataframe\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# Get a list of all dataframes\n",
    "dfs = list(guiamets_dfs.values())\n",
    "\n",
    "# Use reduce to merge all dataframes\n",
    "guiamets_df = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=\"DateTime\"), dfs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with interpolation\n",
    "df_fill = guiamets_df.copy()\n",
    "df_fill.set_index(\"DateTime\", inplace=True)\n",
    "df_fill = df_fill.interpolate(method=\"time\", limit_direction=\"both\")\n",
    "df_fill.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data for each feature\n",
    "for feature in guiamets_dfs.keys():\n",
    "    df_fill[feature + \"_is_missing\"] = df_fill[feature].isna()\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(\n",
    "        data=df_fill,\n",
    "        x=\"DateTime\",\n",
    "        y=feature,\n",
    "        label=feature + \" imputed\",\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        data=guiamets_df,\n",
    "        x=\"DateTime\",\n",
    "        y=feature,\n",
    "        label=feature,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    missing_values_perc = (\n",
    "        df_fill[feature + \"_is_missing\"].sum() / df_fill.shape[0]\n",
    "    ) * 100\n",
    "    missing_values_perc = missing_values_perc.round(2)\n",
    "\n",
    "    plt.title(\n",
    "        feature\n",
    "        + \" - \"\n",
    "        + str(missing_values_perc)\n",
    "        + \"% of missing values\"\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guiamets_df = df_fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mequinenza Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mequinenza_dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mequinenza_dfs[\"cumulated_rainfall_24h\"].isna().sum() / mequinenza_dfs[\n",
    "    \"cumulated_rainfall_24h\"\n",
    "].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mequinenza_dfs[\"cumulated_rainfall_24h\"].drop(\n",
    "    columns=[\"Fecha m�ximo\", \"M�ximo\", \"Fecha acumulado\"], inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mequinenza_dfs[\"cumulated_rainfall_24h\"].rename(\n",
    "    columns={\"fecha\": \"DateTime\", \"Acumulado\": \"Average\"}, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mequinenza_dfs[\"cumulated_rainfall_24h\"][\"DateTime\"] = pd.to_datetime(\n",
    "    mequinenza_dfs[\"cumulated_rainfall_24h\"][\"DateTime\"]\n",
    ")\n",
    "mequinenza_dfs[\"cumulated_rainfall_24h\"][\n",
    "    mequinenza_dfs[\"cumulated_rainfall_24h\"].columns.difference(\n",
    "        [\"DateTime\"]\n",
    "    )\n",
    "] = mequinenza_dfs[\"cumulated_rainfall_24h\"][\n",
    "    mequinenza_dfs[\"cumulated_rainfall_24h\"].columns.difference(\n",
    "        [\"DateTime\"]\n",
    "    )\n",
    "].apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the datasets\n",
    "for feature, df in mequinenza_dfs.items():\n",
    "    print(f\"{feature}: {df.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the moment, drop the missing values\n",
    "for feature, df in mequinenza_dfs.items():\n",
    "    mequinenza_dfs[feature] = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers Detection and Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in mequinenza_dfs.items():\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    sns.histplot(data=df[\"Average\"], kde=True)\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in mequinenza_dfs.items():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(data=df, y=\"Average\")\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in mequinenza_dfs.items():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data - Feature-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How I determined acceptable ranges of values for each feature\n",
    "\n",
    "* Daily Cumulated Rainfall: This [link](https://weather-and-climate.com/average-monthly-precipitation-Rainfall,tarragona-catalonia-es,Spain) says that the average monthly amount of precipitation ranges from 20 mm to 80 mm. On worst case scenario (80 mm in a month, which is october), considering that [here](https://weatherspark.com/y/45958/Average-Weather-in-Tarragona-Spain-Year-Round) it says that on average on october it rains ~ 6 days, we can assume that in a day it can rain up to ~ **13 mm. I decided to take this value as a threshold.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daily Cumulated Rainfall\n",
    "\n",
    "UPDATE: no removal of data since I found out that those values are in a valid range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_df = mequinenza_dfs[\"cumulated_rainfall_24h\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(data=rain_df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "plt.axhline(y=threshold, color=\"r\", linestyle=\"--\", label=\"Threshold\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rain_df = rain_df[rain_df[\"Average\"] < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(data=rain_df, x=\"DateTime\", y=\"Average\", label=\"Average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mequinenza_dfs[\"cumulated_rainfall_24h\"] = rain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show uncovered days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in mequinenza_dfs.items():\n",
    "    df = df.set_index(\"DateTime\")\n",
    "\n",
    "    all_dates = pd.date_range(\n",
    "        start=df.index.min(), end=df.index.max(), freq=\"D\"\n",
    "    )\n",
    "    df = df.reindex(all_dates, fill_value=None)\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"DateTime\"}, inplace=True)\n",
    "    mequinenza_dfs[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in mequinenza_dfs.items():\n",
    "    print(feature)\n",
    "    print()\n",
    "    print(df.isna().sum())\n",
    "    print()\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_df = {}\n",
    "\n",
    "for feature, df in mequinenza_dfs.items():\n",
    "    df[\"is_missing\"] = df[\"Average\"].isna()\n",
    "\n",
    "    label = \"\"\n",
    "    if feature == \"cumulated_rainfall_24h\":\n",
    "        label = \"Daily Cumulated Rainfall (mm)\"\n",
    "\n",
    "    missing_values_perc = (df[\"is_missing\"].sum() / df.shape[0]) * 100\n",
    "    missing_values_perc = missing_values_perc.round(2)\n",
    "\n",
    "    missing_values_df[feature] = missing_values_perc\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(\n",
    "        data=df, x=\"DateTime\", y=\"Average\", label=\"Observed Values\"\n",
    "    )\n",
    "\n",
    "    # Get current axis\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Set major ticks format\n",
    "    years = mdates.YearLocator()  # every year\n",
    "    years_fmt = mdates.DateFormatter(\"%Y\")\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(years_fmt)\n",
    "\n",
    "    for date in df[df[\"is_missing\"]][\"DateTime\"]:\n",
    "        plt.axvline(\n",
    "            x=date, ymin=0.01, ymax=0.99, color=\"grey\", alpha=0.1\n",
    "        )\n",
    "\n",
    "    # Plot an empty line with a label for the legend\n",
    "    plt.plot([], [], color=\"grey\", alpha=0.1, label=\"Missing values\")\n",
    "\n",
    "    plt.title(\n",
    "        label + \" - \" + str(missing_values_perc) + \"% of missing values\"\n",
    "    )\n",
    "\n",
    "    plt.ylabel(label)\n",
    "\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "    print(feature)\n",
    "    print(\"N samples:\", df.shape[0])\n",
    "\n",
    "    # compute the number of suspicious values\n",
    "    n_sus = 0\n",
    "    if lower_threshold:\n",
    "        n_sus += df[df[\"Average\"] < lower_threshold].shape[0]\n",
    "\n",
    "    if upper_threshold:\n",
    "        n_sus += df[df[\"Average\"] > upper_threshold].shape[0]\n",
    "\n",
    "    print(\"N suspicious:\", n_sus)\n",
    "\n",
    "missing_values_df = pd.DataFrame(\n",
    "    missing_values_df.items(), columns=[\"Feature\", \"Missing values (%)\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Average column to the feature name for each dataframe\n",
    "# and keep only the DateTime and the feature column\n",
    "for feature, df in mequinenza_dfs.items():\n",
    "    df.rename(columns={\"Average\": feature}, inplace=True)\n",
    "    df = df[[\"DateTime\", feature, \"is_missing\"]]\n",
    "    df.rename(\n",
    "        columns={\"is_missing\": feature + \"_is_missing\"}, inplace=True\n",
    "    )\n",
    "    mequinenza_dfs[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all xerta datasets into a single dataframe\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# Get a list of all dataframes\n",
    "dfs = list(mequinenza_dfs.values())\n",
    "\n",
    "# Use reduce to merge all dataframes\n",
    "mequinenza_df = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=\"DateTime\"), dfs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with interpolation\n",
    "df_fill = mequinenza_df.copy()\n",
    "df_fill.set_index(\"DateTime\", inplace=True)\n",
    "df_fill = df_fill.interpolate(method=\"time\", limit_direction=\"both\")\n",
    "df_fill.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data for each feature\n",
    "for feature in mequinenza_dfs.keys():\n",
    "    df_fill[feature + \"_is_missing\"] = df_fill[feature].isna()\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(\n",
    "        data=df_fill,\n",
    "        x=\"DateTime\",\n",
    "        y=feature,\n",
    "        label=feature + \" imputed\",\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        data=mequinenza_df,\n",
    "        x=\"DateTime\",\n",
    "        y=feature,\n",
    "        label=feature,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    missing_values_perc = (\n",
    "        df_fill[feature + \"_is_missing\"].sum() / df_fill.shape[0]\n",
    "    ) * 100\n",
    "    missing_values_perc = missing_values_perc.round(2)\n",
    "\n",
    "    plt.title(\n",
    "        feature\n",
    "        + \" - \"\n",
    "        + str(missing_values_perc)\n",
    "        + \"% of missing values\"\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mequinenza_df = df_fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xerta Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_dfs.keys()\n",
    "xerta_dfs[\"conductivity\"] = xerta_dfs.pop(\"Conductivity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in xerta_dfs.items():\n",
    "    print(\"Feature:\", feature)\n",
    "    print()\n",
    "    print(\"% missing values:\")\n",
    "    print()\n",
    "    print(df.isna().sum() / df.shape[0])\n",
    "    print()\n",
    "    print(\"Column names:\", df.columns.to_list())\n",
    "    print()\n",
    "    print(\"-\" * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in xerta_dfs.values():\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"Fecha\": \"DateTime\",\n",
    "            \"Promedio\": \"Average\",\n",
    "            \"Máximo\": \"Maximum\",\n",
    "            \"Mínimo\": \"Minimum\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "    df[df.columns.difference([\"DateTime\"])] = df[\n",
    "        df.columns.difference([\"DateTime\"])\n",
    "    ].apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the datasets\n",
    "for feature, df in xerta_dfs.items():\n",
    "    print(f\"{feature}: {df.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the moment, drop the missing values\n",
    "for feature, df in xerta_dfs.items():\n",
    "    xerta_dfs[feature] = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers Detection and Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in xerta_dfs.items():\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    sns.histplot(data=df[\"Average\"], kde=True)\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in xerta_dfs.items():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(data=df, y=\"Average\")\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in xerta_dfs.items():\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "    # if 'Maximum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Maximum', label='Maximum')\n",
    "    # if 'Minimum' in df.columns:\n",
    "    #     sns.lineplot(data=df, x='DateTime', y='Minimum', label='Minimum')\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data - Feature-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How I determined acceptable ranges of values for each feature\n",
    "\n",
    "* Nitrate: the EU [analyzed](https://water.jrc.ec.europa.eu/pdf/ebro-fs.pdf) the nitrate concentration in the Ebro river showing evidence that the range of values measured is valid, with minimum measures around 5 mg/L and maximum of 39 mg/L. Therefore, **no removal is necessary**.\n",
    "\n",
    "* ABS254: unit of measure needed in order to understand if the range of values is valid. If it is measured in m^-1 then it the values are in a valid domain. **We dediced to take 43 as a threshold value as it removes peak measurements that consists of a single day measurement and the nearby days have much lower measurements.**\n",
    "\n",
    "* pH: no outliers are visible from the plot, the range of values is in a valid domain.\n",
    "\n",
    "* Ammonium: the EU [analyzed](https://www.eea.europa.eu/publications/topic_report_1996_4/) the average ammonium concentration for the biggest rivers in Europe, **with an average value for the Ebro river of 1 mg/L. So I decided to take 1 as the threshold for this measure.** It is also visible from the plot that there are some outliers. \n",
    "\n",
    "* Dissolved Oxygen: compared to other European rivers ([[1]](https://www.eea.europa.eu/help/glossary/semide-emwis-thesaurus/dissolved-oxygen) [[2]](https://www.nature.com/articles/s41558-023-01793-3.epdf?sharing_token=9FHw4vs9ayQDshsDGgw2YdRgN0jAjWel9jnR3ZoTv0N_UAFixjh8yBKAAv5SFFi5TZqeEarq8OCLvF2MOwUvnjpgszm-R5dkD1f1gBUn4ekry_rdvkaYaFttq-a3c_LSIIKRC1QfCVCpMu_ayGcOH4TMz8rleqgElh88xKQM0dBT-DGm7KbFzOvy-bkWM6Jk9T5xJFx05CGT-dZ63W2867oF1IE9pLwJuzpmyfBZaJg%3D&tracking_referrer=www.newscientist.com)), the range of values is considered valid.\n",
    "\n",
    "* Conductivity: the range of values is valid. Therefore, **no removal is necessary.**\n",
    "\n",
    "* Redox Potential: in [this](https://link.springer.com/chapter/10.1007/978-3-662-04080-5_1) ORP book, it is said that the range of ORP can vary from -400 to 800 mV, so the domain is considered valid.\n",
    "\n",
    "* Turbidity: [DataStream](https://datastream.org/en-ca/guidebook/turbidity#:~:text=Turbidity%20values%20less%20than%2010,be%20more%20than%20100%20NTU.) says that high levels of turbidity are > 100 NTU. [In-Situ](https://in-situ.com/us/faq/water-quality-information/what-are-typical-turbidity-values-in-natural-environments#:~:text=Turbidity%20values%20in%20natural%20environments%20can%20range%20from%20as%20low,a%20major%20storm%20runoff%20event.) says that levels of turbidity > 100 NTU are unsafe for most aquatic life. [Wikipedia](https://in-situ.com/us/faq/water-quality-information/what-are-typical-turbidity-values-in-natural-environments#:~:text=Turbidity%20values%20in%20natural%20environments%20can%20range%20from%20as%20low,a%20major%20storm%20runoff%20event.) says that the Ebro river has a wide ecosystem. Given these considerations, **I decided to consider valid the range of values between 0 and 150 NTU**.\n",
    "\n",
    "* Water Temperature: same as conductivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ABS254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df = xerta_dfs[\"ABS254\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(data=abs_df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "plt.axhline(y=threshold, color=\"r\", linestyle=\"--\", label=\"Threshold\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df = abs_df[abs_df[\"Average\"] < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(data=abs_df, x=\"DateTime\", y=\"Average\", label=\"Average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_dfs[\"ABS254\"] = abs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ammonium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ammon_df = xerta_dfs[\"Ammonium\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(data=ammon_df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "plt.axhline(y=threshold, color=\"r\", linestyle=\"--\", label=\"Threshold\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ammon_df = ammon_df[ammon_df[\"Average\"] < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(data=ammon_df, x=\"DateTime\", y=\"Average\", label=\"Average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_dfs[\"Ammonium\"] = ammon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turbidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turb_df = xerta_dfs[\"turbidity\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.lineplot(data=turb_df, x=\"DateTime\", y=\"Average\", label=\"Average\")\n",
    "plt.axhline(y=threshold, color=\"r\", linestyle=\"--\", label=\"Threshold\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turb_df = turb_df[turb_df[\"Average\"] < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(data=turb_df, x=\"DateTime\", y=\"Average\", label=\"Average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_dfs[\"turbidity\"] = turb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show uncovered days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in xerta_dfs.items():\n",
    "    df = df.set_index(\"DateTime\")\n",
    "\n",
    "    all_dates = pd.date_range(\n",
    "        start=df.index.min(), end=df.index.max(), freq=\"D\"\n",
    "    )\n",
    "    df = df.reindex(all_dates, fill_value=None)\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"DateTime\"}, inplace=True)\n",
    "    xerta_dfs[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, df in xerta_dfs.items():\n",
    "    print(feature)\n",
    "    print()\n",
    "    print(df.isna().sum())\n",
    "    print()\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_df = {}\n",
    "\n",
    "for feature, df in xerta_dfs.items():\n",
    "    df[\"is_missing\"] = df[\"Average\"].isna()\n",
    "\n",
    "    lower_threshold = None\n",
    "    upper_threshold = None\n",
    "\n",
    "    label = feature\n",
    "    if feature == \"nitrate\":\n",
    "        label = \"Nitrate (mg/L)\"\n",
    "\n",
    "    elif feature == \"ABS254\":\n",
    "        label = \"UVA254\"\n",
    "        upper_threshold = 43\n",
    "\n",
    "    elif feature == \"Ammonium\":\n",
    "        label = \"Ammonium (mg/L)\"\n",
    "        upper_threshold = 1\n",
    "\n",
    "    elif feature == \"conductivity\":\n",
    "        label = \"Conductivity (µS/cm)\"\n",
    "\n",
    "    elif feature == \"turbidity\":\n",
    "        label = \"Turbidity (NTU)\"\n",
    "        upper_threshold = 150\n",
    "\n",
    "    elif feature == \"dissolvedoxygen\":\n",
    "        label = \"Dissolved Oxygen (mg/L)\"\n",
    "\n",
    "    elif feature == \"redoxpotential\":\n",
    "        label = \"Redox Potential (mV)\"\n",
    "\n",
    "    elif feature == \"watertemperature\":\n",
    "        label = \"Water Temperature (°C)\"\n",
    "\n",
    "    missing_values_perc = (df[\"is_missing\"].sum() / df.shape[0]) * 100\n",
    "    missing_values_perc = missing_values_perc.round(2)\n",
    "\n",
    "    missing_values_df[feature] = missing_values_perc\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(\n",
    "        data=df, x=\"DateTime\", y=\"Average\", label=\"Observed Values\"\n",
    "    )\n",
    "\n",
    "    # Get current axis\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # Set major ticks format\n",
    "    years = mdates.YearLocator()  # every year\n",
    "    years_fmt = mdates.DateFormatter(\"%Y\")\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(years_fmt)\n",
    "\n",
    "    for date in df[df[\"is_missing\"]][\"DateTime\"]:\n",
    "        plt.axvline(\n",
    "            x=date, ymin=0.01, ymax=0.99, color=\"grey\", alpha=0.1\n",
    "        )\n",
    "\n",
    "    # Plot an empty line with a label for the legend\n",
    "    plt.plot([], [], color=\"grey\", alpha=0.1, label=\"Missing values\")\n",
    "\n",
    "    if lower_threshold:\n",
    "        plt.axhline(\n",
    "            y=lower_threshold,\n",
    "            color=\"purple\",\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Lower Threshold: {lower_threshold}\",\n",
    "        )\n",
    "\n",
    "    if upper_threshold:\n",
    "        plt.axhline(\n",
    "            y=upper_threshold,\n",
    "            color=\"r\",\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Upper Threshold: {upper_threshold}\",\n",
    "        )\n",
    "\n",
    "    plt.title(\n",
    "        label + \" - \" + str(missing_values_perc) + \"% of missing values\"\n",
    "    )\n",
    "\n",
    "    plt.ylabel(label)\n",
    "\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "    print(feature)\n",
    "    print(\"N samples:\", df.shape[0])\n",
    "\n",
    "    # compute the number of suspicious values\n",
    "    n_sus = 0\n",
    "    if lower_threshold:\n",
    "        n_sus += df[df[\"Average\"] < lower_threshold].shape[0]\n",
    "\n",
    "    if upper_threshold:\n",
    "        n_sus += df[df[\"Average\"] > upper_threshold].shape[0]\n",
    "\n",
    "    print(\"N suspicious:\", n_sus)\n",
    "\n",
    "missing_values_df = pd.DataFrame(\n",
    "    missing_values_df.items(), columns=[\"Feature\", \"Missing values (%)\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Average column to the feature name for each dataframe\n",
    "# and keep only the DateTime and the feature column\n",
    "for feature, df in xerta_dfs.items():\n",
    "    df.rename(columns={\"Average\": feature}, inplace=True)\n",
    "    df = df[[\"DateTime\", feature, \"is_missing\"]]\n",
    "    df.rename(\n",
    "        columns={\"is_missing\": feature + \"_is_missing\"}, inplace=True\n",
    "    )\n",
    "    xerta_dfs[feature] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all xerta datasets into a single dataframe\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# Get a list of all dataframes\n",
    "dfs = list(xerta_dfs.values())\n",
    "\n",
    "# Use reduce to merge all dataframes\n",
    "xerta_df = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=\"DateTime\"), dfs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with interpolation\n",
    "df_fill = xerta_df.copy()\n",
    "df_fill.set_index(\"DateTime\", inplace=True)\n",
    "df_fill = df_fill.interpolate(method=\"time\", limit_direction=\"both\")\n",
    "df_fill.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data for each feature\n",
    "for feature in xerta_dfs.keys():\n",
    "    df_fill[feature + \"_is_missing\"] = df_fill[feature].isna()\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(\n",
    "        data=df_fill,\n",
    "        x=\"DateTime\",\n",
    "        y=feature,\n",
    "        label=feature + \" imputed\",\n",
    "    )\n",
    "    sns.lineplot(\n",
    "        data=xerta_df, x=\"DateTime\", y=feature, label=feature, alpha=0.5\n",
    "    )\n",
    "\n",
    "    missing_values_perc = (\n",
    "        df_fill[feature + \"_is_missing\"].sum() / df_fill.shape[0]\n",
    "    ) * 100\n",
    "    missing_values_perc = missing_values_perc.round(2)\n",
    "\n",
    "    plt.title(\n",
    "        feature\n",
    "        + \" - \"\n",
    "        + str(missing_values_perc)\n",
    "        + \"% of missing values\"\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df = df_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop boolean columns\n",
    "tortosa_df = tortosa_df[\n",
    "    tortosa_df.columns[~tortosa_df.columns.str.contains(\"_is_missing\")]\n",
    "]\n",
    "\n",
    "guiamets_df = guiamets_df[\n",
    "    guiamets_df.columns[\n",
    "        ~guiamets_df.columns.str.contains(\"_is_missing\")\n",
    "    ]\n",
    "]\n",
    "\n",
    "mequinenza_df = mequinenza_df[\n",
    "    mequinenza_df.columns[\n",
    "        ~mequinenza_df.columns.str.contains(\"_is_missing\")\n",
    "    ]\n",
    "]\n",
    "\n",
    "xerta_df = xerta_df[\n",
    "    xerta_df.columns[~xerta_df.columns.str.contains(\"_is_missing\")]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Parameters Comparison, Unique Dataset Built and Monthly Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use same time period for all data\n",
    "min_date = max(\n",
    "    tortosa_df[\"DateTime\"].min(),\n",
    "    guiamets_df[\"DateTime\"].min(),\n",
    "    mequinenza_df[\"DateTime\"].min(),\n",
    "    xerta_df[\"DateTime\"].min(),\n",
    ")\n",
    "max_date = min(\n",
    "    tortosa_df[\"DateTime\"].max(),\n",
    "    guiamets_df[\"DateTime\"].max(),\n",
    "    mequinenza_df[\"DateTime\"].max(),\n",
    "    xerta_df[\"DateTime\"].max(),\n",
    ")\n",
    "\n",
    "tortosa_df = tortosa_df[\n",
    "    (tortosa_df[\"DateTime\"] >= min_date)\n",
    "    & (tortosa_df[\"DateTime\"] <= max_date)\n",
    "]\n",
    "guiamets_df = guiamets_df[\n",
    "    (guiamets_df[\"DateTime\"] >= min_date)\n",
    "    & (guiamets_df[\"DateTime\"] <= max_date)\n",
    "]\n",
    "mequinenza_df = mequinenza_df[\n",
    "    (mequinenza_df[\"DateTime\"] >= min_date)\n",
    "    & (mequinenza_df[\"DateTime\"] <= max_date)\n",
    "]\n",
    "xerta_df = xerta_df[\n",
    "    (xerta_df[\"DateTime\"] >= min_date)\n",
    "    & (xerta_df[\"DateTime\"] <= max_date)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare common variables\n",
    "\n",
    "Common variables are:\n",
    "* cumulated_rainfall_24h\n",
    "* watertemperature\n",
    "* conductivity\n",
    "\n",
    "The idea is to combine every variable in a single dataset, which in this case is the Xerta dataset, firstly by comparing the redundant variables between each site and secondly by merging the selected variables into the Xerta df.\n",
    "\n",
    "To compare common variables, the same time period must be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulated Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_variable = \"cumulated_rainfall_24h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=guiamets_df, label=\"Guiamets\"\n",
    ")\n",
    "# sns.lineplot(\n",
    "#     x=\"DateTime\",\n",
    "#     y=common_variable,\n",
    "#     data=mequinenza_df,\n",
    "#     label=\"Mequinenza\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tortosa - Mequinenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(\n",
    "    tortosa_df[common_variable],\n",
    "    mequinenza_df[common_variable],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tortosa - Guiamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pears, _ = stats.pearsonr(\n",
    "    tortosa_df[common_variable],\n",
    "    guiamets_df[common_variable],\n",
    ")\n",
    "\n",
    "pears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mequinenza - Guiamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(\n",
    "    mequinenza_df[common_variable], guiamets_df[common_variable]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tortosa - Mequinenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        tortosa_df[common_variable], mequinenza_df[common_variable]\n",
    "    )\n",
    ")\n",
    "rmse / (tortosa_df[common_variable].max() - tortosa_df[common_variable].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tortosa - Guiamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        tortosa_df[common_variable], guiamets_df[common_variable]\n",
    "    )\n",
    ")\n",
    "rmse / (tortosa_df[common_variable].max() - tortosa_df[common_variable].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=guiamets_df, label=\"Guiamets\"\n",
    ")\n",
    "# sns.lineplot(\n",
    "#     x=\"DateTime\",\n",
    "#     y=common_variable,\n",
    "#     data=mequinenza_df,\n",
    "#     label=\"Mequinenza\",\n",
    "# )\n",
    "\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"Pearson Coefficient = {pears:.2f}\",\n",
    "        f\"RMSD = {rmse:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    tortosa_df[\"DateTime\"].iloc[0],\n",
    "    85,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Daily Cumulated Rainfall (mm)\")\n",
    "plt.title(\"Daily Cumulated Rainfall: Tortosa vs Guiamets\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_variable = \"watertemperature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, p_value = stats.pearsonr(\n",
    "    tortosa_df[common_variable], xerta_df[common_variable]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=xerta_df, label=\"Xerta\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "\n",
    "# add textbox with correlation value\n",
    "text_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Pearson correlation = {value:.4f}\",\n",
    "        f\"P-value = {p_value:.4f}\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "# plt.text(\n",
    "#     xerta_df[\"DateTime\"].iloc[60],\n",
    "#     29,\n",
    "#     s=text_string,\n",
    "#     fontsize=12,\n",
    "#     bbox=props,\n",
    "# )\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Water temperature (°C)\")\n",
    "plt.title(\"Water temperature: Xerta vs Tortosa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pears, _ = stats.pearsonr(\n",
    "    tortosa_df[common_variable], xerta_df[common_variable]\n",
    ")\n",
    "\n",
    "pears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        tortosa_df[common_variable], xerta_df[common_variable]\n",
    "    )\n",
    ")\n",
    "rmse / (\n",
    "    tortosa_df[common_variable].max()\n",
    "    - tortosa_df[common_variable].min()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=xerta_df, label=\"Xerta\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"Pearson Coefficient = {pears:.3f}\",\n",
    "        f\"RMSD = {rmse:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    tortosa_df[\"DateTime\"].iloc[60],\n",
    "    29,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Water temperature (°C)\")\n",
    "plt.title(\"Water temperature: Xerta vs Tortosa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_variable = \"conductivity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=xerta_df, label=\"Xerta\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Conductivity (µS/cm)\")\n",
    "plt.title(\"Conductivity: Xerta vs Tortosa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pears, _ = stats.pearsonr(\n",
    "    tortosa_df[common_variable], xerta_df[common_variable]\n",
    ")\n",
    "\n",
    "pears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        tortosa_df[common_variable], xerta_df[common_variable]\n",
    "    )\n",
    ")\n",
    "rmse / (\n",
    "    tortosa_df[common_variable].max()\n",
    "    - tortosa_df[common_variable].min()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=xerta_df, label=\"Xerta\"\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=\"DateTime\", y=common_variable, data=tortosa_df, label=\"Tortosa\"\n",
    ")\n",
    "\n",
    "props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "\n",
    "text_string = \"\\n\".join(\n",
    "    (\n",
    "        f\"Pearson Coefficient = {pears:.3f}\",\n",
    "        f\"RMSD = {rmse:.2f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.text(\n",
    "    tortosa_df[\"DateTime\"].iloc[0],\n",
    "    1800,\n",
    "    s=text_string,\n",
    "    fontsize=12,\n",
    "    bbox=props,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Conductivity (µS/cm)\")\n",
    "plt.title(\"Conductivity: Xerta vs Tortosa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Unique Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# water temperature and conductivity are better in the xerta dataset so no need to merge with tortosa\n",
    "\n",
    "# I decided to take the rainfall from tortosa since it is the closest to the xerta station\n",
    "\n",
    "xerta_df[\"cumulated_rainfall_24h\"] = tortosa_df[\n",
    "    \"cumulated_rainfall_24h\"\n",
    "].values\n",
    "xerta_df[\"environment_temperature\"] = guiamets_df[\n",
    "    \"environmental_temperature\"\n",
    "].values\n",
    "xerta_df[\"flowriver\"] = tortosa_df[\"flowriver\"].values\n",
    "\n",
    "xerta_df.rename(\n",
    "    columns={\n",
    "        \"cumulated_rainfall_24h\": \"Daily Cumulated Rainfall\",\n",
    "        \"watertemperature\": \"Water Temperature\",\n",
    "        \"environment_temperature\": \"Air Temperature\",\n",
    "        \"flowriver\": \"Flow River\",\n",
    "        \"conductivity\": \"Conductivity\",\n",
    "        \"dissolvedoxygen\": \"Dissolved Oxygen\",\n",
    "        \"nitrate\": \"Nitrate\",\n",
    "        \"redoxpotential\": \"Redox Potential\",\n",
    "        \"turbidity\": \"Turbidity\",\n",
    "        \"Ammonium\": \"Ammonium\",\n",
    "        \"ABS254\": \"Absorbance 254nm\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop first 3 rows of xerta_df since they are the only rows for august 2012\n",
    "xerta_df = xerta_df.iloc[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.set_index(\"DateTime\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add unit of measurement to the columns\n",
    "xerta_df.rename(\n",
    "    columns={\n",
    "        \"Daily Cumulated Rainfall\": \"Cumulated Rainfall (mm)\",\n",
    "        \"Water Temperature\": \"Water Temperature (°C)\",\n",
    "        \"Air Temperature\": \"Air Temperature (°C)\",\n",
    "        \"Flow River\": \"Flow River Rate (m³/s)\",\n",
    "        \"Conductivity\": \"Conductivity (µS/cm)\",\n",
    "        \"Dissolved Oxygen\": \"Dissolved Oxygen (mg/L)\",\n",
    "        \"Nitrate\": \"Nitrate (mg/L)\",\n",
    "        \"Redox Potential\": \"Redox Potential (mV)\",\n",
    "        \"Turbidity\": \"Turbidity (NTU)\",\n",
    "        \"Ammonium\": \"Ammonium (mg/L)\",\n",
    "        \"Absorbance 254nm\": \"UVA254 (1/m)\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an info dataframe to store the information about the dataset\n",
    "info_df = pd.DataFrame(\n",
    "    index=pd.Index(\n",
    "        [\n",
    "            \"N Samples\",\n",
    "            \"% Missing Values\",\n",
    "            \"Frequency (days)\",\n",
    "            \"Mean\",\n",
    "            \"Std\",\n",
    "            \"Start Date\",\n",
    "            \"End Date\",\n",
    "        ],\n",
    "        name=\"Info\",\n",
    "    ),\n",
    "    columns=xerta_df.columns,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the information in the station_info_df\n",
    "for column in xerta_df.columns:\n",
    "    df = xerta_df[column].copy()\n",
    "\n",
    "    start_date = df.dropna().index.min().strftime(\"%Y-%m-%d\")\n",
    "    end_date = df.dropna().index.max().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    df = df[start_date:end_date]\n",
    "\n",
    "    missing_values = df.isna().sum() / df.shape[0] * 100\n",
    "\n",
    "    info_df.loc[\"N Samples\", column] = (\n",
    "        xerta_df[column].dropna().shape[0]\n",
    "    )\n",
    "    info_df.loc[\n",
    "        \"% Missing Values\", column\n",
    "    ] = missing_values\n",
    "    info_df.loc[\"Frequency (days)\", column] = (\n",
    "        xerta_df.index.to_series().diff().value_counts().index[0].days\n",
    "    )\n",
    "    \n",
    "    info_df.loc[\"Mean\",  column] = df.mean()\n",
    "    info_df.loc[\"Std\", column] = df.std()\n",
    "    \n",
    "    info_df.loc[\"Start Date\", column] = start_date\n",
    "    info_df.loc[\"End Date\", column] = end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample to monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df = xerta_df.resample(\"ME\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in xerta_df.columns:\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.lineplot(data=xerta_df, x=xerta_df.index, y=feature, label=feature)\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerta_df.to_excel(os.path.join(clean_data_folder, \"xerta.xlsx\"), index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safecrew-t4-1-nom-anthropogenic-impact-1EhQKKig-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
